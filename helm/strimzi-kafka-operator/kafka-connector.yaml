apiVersion: "kafka.strimzi.io/v1alpha1"
kind: "KafkaConnector"
metadata:
  name: "inventory-connector"
  labels:
    strimzi.io/cluster: my-connect-cluster
spec:
  class: io.debezium.connector.mysql.MySqlConnector
  tasksMax: 1
  config:
    database.hostname: mysql # MySQL 서비스 이름
    database.port: "3306"
    database.user: "${file:/opt/kafka/external-configuration/connector-config/debezium-mysql-credentials.properties:mysql_username}"
    database.password: "${file:/opt/kafka/external-configuration/connector-config/debezium-mysql-credentials.properties:mysql_password}"
    database.server.id: "184054"
    database.server.name: "mysql_server"
    database.whitelist: "my_database"  # 캡처할 데이터베이스 이름
    database.history.kafka.bootstrap.servers: "my-cluster-kafka-bootstrap:9092"
    database.history.kafka.topic: "schema-changes.inventory"
    include.schema.changes: "true" 

# ---

# apiVersion: kafka.strimzi.io/v1beta1
# kind: KafkaConnector
# metadata:
#   name: s3-sink-connector
#   labels:
#     strimzi.io/cluster: my-cluster  # Kafka 클러스터 이름
# spec:
#   class: io.confluent.connect.s3.S3SinkConnector  # S3 Sink Connector 클래스
#   tasksMax: 1
#   config:
#     topics: mysql_server.my_database.users  # Kafka에서 데이터를 가져올 토픽 이름
#     flush.size: "1000"
#     s3.bucket.name: your-s3-bucket  # S3 버킷 이름
#     s3.region: your-region  # S3 지역
#     key.converter: org.apache.kafka.connect.json.JsonConverter  # 키 변환기
#     value.converter: org.apache.kafka.connect.json.JsonConverter  # 값 변환기
#     value.converter.schemas.enable: "false"  # 스키마 비활성화 (필요에 따라 설정)
